# Working with dataset helpers

`parseColumns` returns a JSON structure that represents your dataset in a column-centric format. The helpers in `core/json/factors.js` and `core/json/driver.js` make it easy to read from that structure, build new columns, and persist variants generated by `variants.createVariant`.

## Create a base column from raw values

`factors.makeColumn(values, options)` accepts an array of raw strings and returns the encoded column payload that the rest of the stack expects.

~~~js
import factors from '../../core/json/factors.js';

const genderColumn = factors.makeColumn([
  'female',
  'male',
  '',
  'female'
], {
  col_type: 'q',
  var_label: 'Gender (original)',
  baseVariantMeta: { source: 'questionnaire' }
});

console.log(genderColumn.col_type); // 'q'
console.log(genderColumn.col_vars[0].var_label); // 'Gender (original)'
~~~

Key options:
 - `decodeColumn(column)` turns any column or variant back into its raw array, handy right after `makeColumn` or `createVariant`.
- `col_type` / `col_sep` override the inferred type and list separator.
- `encode` skips factor encoding when you want to store raw strings unchanged.
- `includeBaseVariant` and `baseVariantLabel` let you control whether the column seeds an "Original" variant automatically.
- `col_vars` appends additional variants when you already have derived columns ready to store.

## Read values from the parsed database

Once the dataset has been processed by `parseColumns`, use `driver.getColumnValues(database, colHash, variantIndex)` to retrieve the decoded values for any column or variant.

Need just the column metadata? Call `driver.getColumn(database, colHash)` before decoding or inspecting variants.
~~~js
import driver from '../../core/json/driver.js';

const { column, variant, rawValues } = driver.getColumnValues(database, 'col_sex_hash');

console.log(column.col_label); // existing column metadata
console.log(rawValues.slice(0, 3)); // decoded values ready for transforms

// Fetch the first derived variant if it exists
const secondPass = driver.getColumnValues(database, 'col_sex_hash', 1);
console.log(secondPass.variant?.var_label);
~~~

The helper normalizes separators, decodes list columns, and falls back to the base column values when `variantIndex` is omitted.

## Append a new variant to the dataset

After calling `variants.createVariant`, persist the result with `driver.addVariant(database, colHash, newVariant)`.

~~~js
import variants from '../../core/json/variants.js';

const cleaned = variants.createVariant(column, {
  kind: 'search_replace',
  var_label: 'Gender (cleaned)',
  replacements: [
    { search: 'female', replace: 'Female' },
    { search: 'male', replace: 'Male' }
  ],
  sortByFrequency: true
});

driver.addVariant(database, column.col_hash, cleaned);
~~~

If the target column does not yet have a `col_vars` array, `addVariant` seeds an "Original" variant for you before appending the new entry. The function throws when the column hash cannot be found, so make sure you carry the hash returned by `parseColumns` through your workflow.

## End-to-end recipe

~~~js
import factors from '../../core/json/factors.js';
import variants from '../../core/json/variants.js';
import driver from '../../core/json/driver.js';

// 1. Build the base column from raw data
const incomeColumn = factors.makeColumn(rawIncomeArray, {
  col_type: 'n',
  var_label: 'Household income'
});

database.columns.push({
  col_hash: 'col_income_hash',
  col_label: 'Household income',
  ...incomeColumn
});

// 2. Read the decoded values when needed
const { rawValues } = driver.getColumnValues(database, 'col_income_hash');

// 3. Create a variant and attach it to the same column
const logVariant = variants.createVariant({
  ...incomeColumn,
  col_vars: incomeColumn.col_vars
}, {
  kind: 'transform',
  var_label: 'Household income (log10)',
  forceNumeric: {},
  transform: { fn: 'log10' }
});

driver.addVariant(database, 'col_income_hash', logVariant);
~~~

You now have a base column plus a derived log-transformed variant stored alongside the dataset. Downstream consumers — Bubble workflows, analysis scripts, or exports — can pick the appropriate variant by index.

## Tips for contributors

- Always treat `col_hash` as the stable identifier when moving data between helpers.
- `cloneColValues` is available via `variants.cloneColValues` when you need to duplicate the encoded payload before mutating it.
- Use the warnings collected in `variant.meta.warnings` to surface issues back to users (e.g., dropped rows during numeric coercion).
- Pair these helpers with `variants.VARIANT_TEMPLATES` to offer consistent UI presets for common clean-up steps.

With these tools, you can script complete "read -> transform -> store" workflows without mutating the original dataset, keeping Statz's variant system transparent and reproducible.
